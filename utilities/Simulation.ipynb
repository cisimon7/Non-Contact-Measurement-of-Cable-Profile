{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Simulation.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPUSPZ0I1YZaQA453JJ/TKq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cisimon7/Non-Contact-Measurement-of-Cable-Profile/blob/main/utilities/Simulation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DYmt2PmWcBb7"
      },
      "source": [
        "import numpy as np\r\n",
        "import torch"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_xS8UHMmcPIw"
      },
      "source": [
        "def catenary(x, a):\r\n",
        "    return a * torch.cosh((x + 1) / a)          # Assume the form of catenary\r\n",
        "\r\n",
        "\"\"\"\r\n",
        "Is it assumed that alpha = 1 and beta = 0 ?\r\n",
        "if true, why is that?\r\n",
        "\r\n",
        "I guess this is the real life form of the cable, which can actually be any shape \r\n",
        "but must be of the catenary form.\r\n",
        "\r\n",
        "Our goal is to be able to find this equation, i.e a = a, alpha = 1 and beta = 0\r\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vr5x-swgcQeH"
      },
      "source": [
        "def to_image(vector_x, camera_matrix):\r\n",
        "    \"\"\"\r\n",
        "    Projects 3D vectors to 2D image coordinates given camera configuration\r\n",
        "    This function imitate how points are formed from 3D world to a camera 2D plane\r\n",
        "\r\n",
        "    camera_matrix: a 3X3 matrix defined by the camera intrinsic parameters\r\n",
        "    The extrinsic parameters have been fixed here\r\n",
        "    \"\"\"\r\n",
        "    R = torch.Tensor(np.identity(3))            # Camera Rotation matrix, assume R is identity (3 X 3) \r\n",
        "    t = torch.Tensor([0, 0, 100]).unsqueeze(1)  # 3D coordinate; assume to be [0 0 100]. This means camera is facing object directly with z representing distance of camera to object \r\n",
        "\r\n",
        "    ext_params = torch.cat((R, t), 1)           # Get Q|t. (4 X 3)\r\n",
        "    img = camera_matrix @ ext_params @ vector_x # C[Q|T]x. Returns w[x, y, 1] where w is the scale factor. Possible Error: (vector_z, 1) @ ext_params @ camera_matrix\r\n",
        "    img = img / img[-1]                         # divide by z to get coordinates \r\n",
        "    return img\r\n",
        "\r\n",
        "# https://www.mathworks.com/help/vision/ug/camera-calibration.html"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ftTi8_RcR1Z"
      },
      "source": [
        "\"\"\"\r\n",
        "Why adding noise ???? \r\n",
        "Because in real life, our measurement cannot be very accurate\r\n",
        "\"\"\"\r\n",
        "def add_noise(*vector_u):\r\n",
        "    # Adds noise from N(0, 1) to all vectors in the input\r\n",
        "    return list(map(lambda x: x + torch.normal(0, 1, (2,)), vector_u))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nscnpqVscT9Z"
      },
      "source": [
        "def calculate_error(u, u_hat, error_func=lambda x: torch.norm(x, 2)):\r\n",
        "  \"\"\"\r\n",
        "  Calculates error function, given by the user (second norm by default)\r\n",
        "  u     : actual image coordinate in 2D world \r\n",
        "  u_hat : noisy image coordinate in 2D world \r\n",
        "  \"\"\"\r\n",
        "  return error_func(u - u_hat)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2gomh1czcVDw"
      },
      "source": [
        "def calculate_step(a, x_1, x_2, camera_matrix):\r\n",
        "    # One step of the optimization\r\n",
        "\r\n",
        "    # Base on guess, this is representing the y position of the real life cable\r\n",
        "    y_1 = catenary(x_1, a)           \r\n",
        "    y_2 = catenary(x_2, a)\r\n",
        "\r\n",
        "    # Stack values of xs and ys to get the 3D vector (z=0 as they are in the same plane)\r\n",
        "    zero, one = torch.tensor(0, dtype=torch.float32), torch.tensor(1, dtype=torch.float32)\r\n",
        "\r\n",
        "    # Notice that the z value has been set to zero, what does this mean to how we place our axis during the actual measurement\r\n",
        "    # Why one is added can be seen in the camera calibration link\r\n",
        "    vector_x1 = torch.stack((x_1, y_1, zero, one))\r\n",
        "    vector_x2 = torch.stack((x_2, y_2, zero, one))\r\n",
        "\r\n",
        "    # Project to the image space\r\n",
        "    u1 = to_image(vector_x1, camera_matrix)[:2]\r\n",
        "    u2 = to_image(vector_x2, camera_matrix)[:2]\r\n",
        "\r\n",
        "    return u1, u2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3qJrDFuFb5Bn"
      },
      "source": [
        "# Class for simulation steps\r\n",
        "class Simulation:\r\n",
        "    # We need initial assumption of a, x1,x2 and camera matrix\r\n",
        "    def __init__(self, a, x1, x2, camera_matrix):\r\n",
        "        self.camera_matrix = camera_matrix\r\n",
        "\r\n",
        "        # Calculate the target 'tilde u1' and 'tilde u2' ???\r\n",
        "        self.perfect_u1, self.perfect_u2 = add_noise(*calculate_step(a, x1, x2, camera_matrix))\r\n",
        "\r\n",
        "        # Trainables a, x1 and x2\r\n",
        "        self.a = torch.tensor(1, dtype=torch.float32, requires_grad=True)\r\n",
        "        self.x_1 = torch.tensor(0, dtype=torch.float32, requires_grad=True)\r\n",
        "        self.x_2 = torch.tensor(0, dtype=torch.float32, requires_grad=True)\r\n",
        "\r\n",
        "        # Init optimizer and learning rate scheduler\r\n",
        "        self.optimizer = torch.optim.SGD([self.a, self.x_1, self.x_2], lr=1e-2)\r\n",
        "        self.scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(self.optimizer, 'min', factor=0.99)\r\n",
        "\r\n",
        "    def calculate_step(self):\r\n",
        "        # One step of the optimization\r\n",
        "        y_1 = catenary(self.x_1, self.a)  # Calculate y1 and y2 values using assumed form of the catenary\r\n",
        "        y_2 = catenary(self.x_2, self.a)\r\n",
        "\r\n",
        "        # Stack values of xs and ys to get the 3D vector (z=0 as they are in the same plane)\r\n",
        "        zero, one = torch.tensor(0, dtype=torch.float32), torch.tensor(1, dtype=torch.float32)\r\n",
        "        vector_x1 = torch.stack((self.x_1, y_1, zero, one))\r\n",
        "        vector_x2 = torch.stack((self.x_2, y_2, zero, one))\r\n",
        "\r\n",
        "        # Project to the image space\r\n",
        "        u1 = to_image(vector_x1, self.camera_matrix)[:2]\r\n",
        "        u2 = to_image(vector_x2, self.camera_matrix)[:2]\r\n",
        "\r\n",
        "        return u1, u2\r\n",
        "\r\n",
        "    def simulate(self, iters=10000, verbosity=10000):\r\n",
        "        # Simulation of convergence\r\n",
        "        for i in range(iters):\r\n",
        "            self.optimizer.zero_grad()\r\n",
        "\r\n",
        "            # Get current u's\r\n",
        "            new_u1, new_u2 = calculate_step(self.a, self.x_1, self.x_2, self.camera_matrix)\r\n",
        "\r\n",
        "            # Calculate loss\r\n",
        "            loss = (calculate_error(self.perfect_u1, new_u1) + calculate_error(self.perfect_u2, new_u2)) / 2\r\n",
        "            if i % verbosity == 0:\r\n",
        "                print(f'Epoch {i}. Loss {loss}')\r\n",
        "\r\n",
        "            loss.backward()\r\n",
        "            self.optimizer.step()\r\n",
        "            self.scheduler.step(loss)\r\n",
        "            \r\n",
        "        return self.a, self.x_1, self.x_2, new_u1, new_u2"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}